{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eyaler/autocoder/blob/main/colab/autocoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Autocoder: a Variational Autoencoder for Spectral Synthesis [Franzson, et al.]\n",
        "### An accessible Google Colab for training, and (interactive) generation!\n",
        "\n",
        "#### Colab by [Eyal Gruss](https://eyalgruss.com) ([@eyaler](https://twitter.com/eyaler?lang=en)\\)\n",
        "#### With a lot of inspiration and guidance from [Nicholas Shaheed](https://nicholasshaheed.com)\n",
        "#### Made at [Stochastic Labs](http://stochasticlabs.org)\n",
        "\n",
        "\n",
        "\"Our motivation for the Autocoder is the artistic need for a simple tool aimed at creative individuals that allows for the manipulation and exploration of any input sound –– harmonic or in-harmonic, monophonic or polyphonic –– in real-time, with minimal time wasted on training and adjustment of network parameters while emphasizing the quality of the synthesized output.\" [Franzson, et al.]\n",
        "\n",
        "\n",
        "##### Paper: https://www.dropbox.com/s/meewllm1rc243ad/icmc_paper_autocoder_final.pdf\n",
        "##### Original repo: https://github.com/franzson/autocoder \n",
        "##### Original Colab: https://colab.research.google.com/github/franzson/autocoder_training/blob/main/autoencoder_simple.ipynb\n",
        "##### Original examples: https://soundcloud.com/david-brynjar-franzson/sets/autocoder-examples\n",
        "##### Recommended to use in MAX/MSP with Nick's plugin: https://github.com/nshaheed/autocoder-expanded\n",
        "##### Shortcut to this Colab: https://bit.ly/autocod"
      ],
      "metadata": {
        "id": "gn02EN-w5HGc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdYCXKCkEspX",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Upload audio file\n",
        "#@markdown Enter a URL to an audio file OR a YouTube or similar site OR leave empty for manual upload (canceling the upload will use a default file)\n",
        "audio = '' #@param {type:'string'}\n",
        "\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "upload_folder = '/content/upload'\n",
        "!rm -rf \"$upload_folder\"\n",
        "!mkdir \"$upload_folder\"\n",
        "%cd \"$upload_folder\"\n",
        "\n",
        "cancelled = False\n",
        "if not audio:\n",
        "  try:\n",
        "    uploaded = files.upload()\n",
        "    input_filename = list(uploaded)[0]\n",
        "  except Exception:\n",
        "    audio = 'https://www.youtube.com/watch?v=GrNue18uWWE'\n",
        "if audio:\n",
        "  if audio.rsplit('.')[-1] in ['mp3','wav','m4a','aac','ogg','flac','wma','aiff','opus','amr','ac3','mp4']:\n",
        "    !wget \"$audio\" \n",
        "    input_filename = audio.rsplit('/')[-1]\n",
        "  else:\n",
        "    !pip install -q youtube-dl\n",
        "    !youtube-dl --no-playlist --extract-audio --audio-format mp3 \"$audio\" -o \"audio.%(ext)s\"\n",
        "    input_filename = 'audio.mp3'\n",
        "input_filename = os.path.join(upload_folder, input_filename)\n",
        "print(input_filename)\n",
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jLMxztkc_XH",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Train model\n",
        "quality = 'MEDIUM QUALITY - TRAINING TIME ROUGHLY 3x DURATION - GOOD ENOUGH FOR MOST THINGS' #@param ['LOW QUALITY - TRAINING TIME ROUGHLY .8x DURATION - GOOD ENOUGH FOR EXPLORATION', 'MEDIUM QUALITY - TRAINING TIME ROUGHLY 3x DURATION - GOOD ENOUGH FOR MOST THINGS', 'HIGH QUALITY - TRAINING TIME ROUGHLY 5x DURATION', 'EXTREME QUALITY - TRAINING TAKES A VERY LONG TIME']\n",
        "start_secs = 0 #@param {type:'number'}\n",
        "duration_from_start_secs = 0 #@param {type:'number'}\n",
        "#@markdown Note: setting duration_from_start_secs=0 will take the full remaining duration \n",
        "duration_from_start_secs = duration_from_start_secs or None\n",
        "\n",
        "if quality == 'LOW QUALITY - TRAINING TIME ROUGHLY .8x DURATION - GOOD ENOUGH FOR EXPLORATION':\n",
        "  batch_size = 1024\n",
        "  regression_patience = 200\n",
        "  learning_rate = .0001\n",
        "  min_delta = .00001\n",
        "  quality = \"low\"\n",
        "elif quality == 'MEDIUM QUALITY - TRAINING TIME ROUGHLY 3x DURATION - GOOD ENOUGH FOR MOST THINGS':\n",
        "  batch_size = 512\n",
        "  regression_patience = 500\n",
        "  learning_rate = .0001\n",
        "  min_delta = .00001\n",
        "  quality = \"medium\"\n",
        "elif quality == 'HIGH QUALITY - TRAINING TIME ROUGHLY 5x DURATION':\n",
        "  batch_size = 256\n",
        "  regression_patience = 1000 \n",
        "  learning_rate = .0001\n",
        "  min_delta = .00001\n",
        "  quality = \"high\"\n",
        "elif quality == 'EXTREME QUALITY - TRAINING TAKES A VERY LONG TIME':\n",
        "  batch_size = 256\n",
        "  regression_patience = 10000000\n",
        "  learning_rate = .0001\n",
        "  min_delta = 0\n",
        "  quality = \"extreme\"\n",
        "\n",
        "\n",
        "%cd /content\n",
        "!pip install -q python_speech_features\n",
        "\n",
        "import librosa\n",
        "import numpy as np\n",
        "import scipy\n",
        "from scipy.signal import hann\n",
        "from python_speech_features.base import get_filterbanks\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "import math\n",
        "import time\n",
        "\n",
        "rate = 44100\n",
        "\n",
        "\n",
        "# ANALYSIS SETTINGS\n",
        "fftsize = 16384\n",
        "windowskip = 1024\n",
        "\n",
        "# MODEL STRUCTURE\n",
        "input_dim = 512\n",
        "intermediate_dim = 1000\n",
        "encoded_dim = 8\n",
        "output_fft_size = 8192\n",
        "\n",
        "\n",
        "def create_mel_filter(fft_size, n_freq_components = 64, start_freq = 300, end_freq = 8000, samplerate = rate):\n",
        "    filterbanks = get_filterbanks(nfilt=n_freq_components,\n",
        "                                           nfft=fft_size, samplerate=samplerate,\n",
        "                                           lowfreq=start_freq, highfreq=end_freq)\n",
        "    mel_inversion_filter = np.ascontiguousarray((filterbanks.T[0:(int(fft_size/2))]).T)\n",
        "    mel_filter = np.ascontiguousarray(np.divide(mel_inversion_filter.T, mel_inversion_filter.sum(axis=1)))\n",
        "\n",
        "    return mel_filter, mel_inversion_filter\n",
        "\n",
        "\n",
        "def initialize(size, melsize):\n",
        "    window = np.zeros((1, size))\n",
        "    window = np.ascontiguousarray(window)\n",
        "    window[0,] = hann(size)\n",
        "    mel_filter, mel_inversion_filter = create_mel_filter(size, melsize, 0, rate//2, rate)\n",
        "    np.nan_to_num(mel_filter, False, nan = 0.0)\n",
        "    np.nan_to_num(mel_inversion_filter, False, nan = 0.0)\n",
        "    return(mel_filter, mel_inversion_filter, window)\n",
        "\n",
        "\n",
        "def convertToBin(data):\n",
        "    return(np.sqrt(np.add(np.multiply(data.real, data.real), np.multiply(data.imag, data.imag))))\n",
        "\n",
        "\n",
        "def spectrogram_to_mel(spectrogram, filter):\n",
        "    mel_spec = np.transpose(filter).dot(np.transpose(spectrogram))\n",
        "    return mel_spec\n",
        "\n",
        "\n",
        "def get_aminmax(X):\n",
        "    return(np.amin(X), np.amax(X))\n",
        "\n",
        "\n",
        "def scale_array_by_amax(X):\n",
        "    return((X - np.amin(X)) / (np.amax(X) - np.amin(X)))\n",
        "\n",
        "\n",
        "def analyze(data, window, mel_filter):\n",
        "    data = np.multiply(data, window)\n",
        "    fftdata = scipy.fft.rfft(data)\n",
        "    ampslize = convertToBin(fftdata)\n",
        "    ampslize = np.ascontiguousarray(ampslize)\n",
        "    #phase = np.angle(fftdata)\n",
        "    melslize = spectrogram_to_mel(ampslize[0,0:int(data.shape[1]/2)], mel_filter)\n",
        "    return(melslize, ampslize[0,0:int(data.shape[1]/2)])\n",
        "\n",
        "\n",
        "def analyze_data(data, filename, fftsize, windowskip, melsize, window, mel_filter):\n",
        "    n_slizes = round(len(data)/windowskip)\n",
        "    output = np.zeros((int((n_slizes - 16))+1, melsize))\n",
        "    output = np.ascontiguousarray(output)\n",
        "    fft_output = np.zeros((int((n_slizes - 16))+1, int(fftsize / 2)))\n",
        "    fft_output = np.ascontiguousarray(fft_output)\n",
        "\n",
        "    in_slize = np.zeros((1, fftsize))\n",
        "    in_slize = np.ascontiguousarray(in_slize)\n",
        "    for i in range(0, (n_slizes - 16)):\n",
        "        in_slize[0] = data[i * windowskip:((i*windowskip) + fftsize)]\n",
        "        output[i,:], fft_output[i,:] = analyze(in_slize, window, mel_filter)\n",
        "\n",
        "    output = np.nan_to_num(output, 0.)\n",
        "    minin, maxin = get_aminmax(output)\n",
        "    output = scale_array_by_amax(output)\n",
        "\n",
        "    np.save(filename + \".npy\", output)\n",
        "    #np.save(filename + \".fft.npy\", fft_output)\n",
        "    return(minin, maxin, output)\n",
        "\n",
        "\n",
        "def sampling(args):\n",
        "    \"\"\"Reparameterization trick by sampling from an isotropic unit Gaussian.\n",
        "    # Arguments\n",
        "        args (tensor): mean and log of variance of Q(z|X)\n",
        "    # Returns\n",
        "        z (tensor): sampled latent vector\n",
        "    \"\"\"\n",
        "    z_mean, z_log_var = args\n",
        "    epsilon = 1e-06\n",
        "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "\n",
        "def init_autoencoder_shallow(input_dim, intermediate_dim, encoded_dim, learning_rate):\n",
        "\n",
        "    input_shape = (input_dim, )\n",
        "    latent_dim = encoded_dim\n",
        "\n",
        "    #print(\"input_shape: \", input_shape)\n",
        "\n",
        "    # VAE model = encoder + decoder\n",
        "    # build encoder model\n",
        "    inputs = tf.keras.Input(shape=input_shape, name='encoder_input')\n",
        "    x = tf.keras.layers.Dense(intermediate_dim, activation='relu', activity_regularizer=tf.keras.regularizers.l1(10e-5), kernel_regularizer=tf.keras.regularizers.l1_l2(l1=1e-5, l2=1e-5))(inputs)\n",
        "\n",
        "    z_mean = tf.keras.layers.Dense(latent_dim, name='z_mean')(x)\n",
        "    z_log_var = tf.keras.layers.Dense(latent_dim, name='z_log_var')(x)\n",
        "\n",
        "    # use reparameterization trick to push the sampling out as input\n",
        "    # note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
        "    z = tf.keras.layers.Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
        "\n",
        "    # instantiate encoder model\n",
        "    encoder = tf.keras.Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
        "    # encoder.summary()\n",
        "\n",
        "    # build decoder model\n",
        "    latent_inputs = tf.keras.Input(shape=(latent_dim,), name='z_sampling')\n",
        "    x = tf.keras.layers.Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
        "    outputs = tf.keras.layers.Dense(input_dim, activation='sigmoid')(x)\n",
        "\n",
        "    # instantiate decoder model\n",
        "    _,mel_inversion_filter = create_mel_filter(output_fft_size, input_dim, 0, rate//2, rate)\n",
        "    mel = K.expand_dims(tf.constant(mel_inversion_filter), 0)\n",
        "    transformed_outputs = tf.keras.layers.Dot(axes=(1,1)) ([outputs, mel])\n",
        "    decoder = tf.keras.Model(latent_inputs, transformed_outputs, name='decoder')\n",
        "    training_decoder = tf.keras.Model(latent_inputs, outputs, name='training_decoder')\n",
        "    # decoder.summary()\n",
        "    # training_decoder.summary()\n",
        "    # instantiate VAE model\n",
        "    training_outputs = training_decoder(encoder(inputs)[2])\n",
        "    outputs = decoder(encoder(inputs)[2])\n",
        "\n",
        "\n",
        "    vae = tf.keras.Model(inputs, [training_outputs,outputs], name='vae_mlp')\n",
        "\n",
        "    reconstruction_loss = tf.keras.losses.binary_crossentropy(inputs, training_outputs)\n",
        "\n",
        "    reconstruction_loss *= input_dim\n",
        "    kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
        "    kl_loss = K.sum(kl_loss, axis=-1)\n",
        "    kl_loss *= -0.5\n",
        "    vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
        "    vae.add_loss(vae_loss)\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    vae.compile(optimizer=opt)\n",
        "    return(vae, encoder, decoder, training_decoder)\n",
        "\n",
        "\n",
        "def get_minmax(encoder, input):\n",
        "    z_encoded = encoder.predict(input)\n",
        "    z_encoded = np.asarray(z_encoded[0], dtype = np.float32)\n",
        "\n",
        "    min = z_encoded.min(axis = 0)\n",
        "    max = z_encoded.max(axis = 0)\n",
        "    scale_mult = np.subtract(max, min)\n",
        "    scale_subtract = min\n",
        "    return(scale_mult, scale_subtract)\n",
        "\n",
        "\n",
        "history = 0\n",
        "\n",
        "\n",
        "def train(filename, vae, encoder, decoder, training_decoder, input, min_delta, regression_patience = 1, batch_size = 4096, deep = 0):\n",
        "    global history\n",
        "    tf.executing_eagerly()\n",
        "    es = tf.keras.callbacks.EarlyStopping(monitor='loss', mode='min', min_delta=min_delta, patience = regression_patience)\n",
        "    history = vae.fit(input,\n",
        "            batch_size = batch_size,\n",
        "            epochs=50000, verbose = 0, callbacks=[es])\n",
        "\n",
        "    vae.save_weights(filename + \".h5\")\n",
        "    scale_mult, scale_subtract = get_minmax(encoder, input)\n",
        "\n",
        "    converter_enc = tf.lite.TFLiteConverter.from_keras_model(encoder)\n",
        "    converter_dec = tf.lite.TFLiteConverter.from_keras_model(decoder)\n",
        "    converter_training_dec = tf.lite.TFLiteConverter.from_keras_model(training_decoder)\n",
        "    tflite_model_enc = converter_enc.convert()\n",
        "    tflite_model_dec = converter_dec.convert()\n",
        "    tflite_model_training_dec = converter_training_dec.convert()\n",
        "\n",
        "    # Save the models\n",
        "    with open(filename + '.enc', 'wb') as f:\n",
        "      f.write(tflite_model_enc)\n",
        "    with open(filename + '.fft.dec', 'wb') as f:\n",
        "      f.write(tflite_model_dec)\n",
        "    with open(filename + '.dec', 'wb') as f:\n",
        "      f.write(tflite_model_training_dec)\n",
        "\n",
        "    return(vae, encoder, decoder, training_decoder, scale_mult, scale_subtract)\n",
        "\n",
        "\n",
        "def write_mm(filename, minin, maxin, scale_mult, scale_subtract, input_dim, intermediate_dim, encoded_dim, deep):\n",
        "    output_ = np.zeros([3, 8])\n",
        "    output_[0] = scale_mult\n",
        "    output_[1] = scale_subtract\n",
        "    output_[2][0] = minin\n",
        "    output_[2][1] = maxin\n",
        "    output_[2][2] = input_dim\n",
        "    output_[2][3] = intermediate_dim\n",
        "    output_[2][4] = encoded_dim\n",
        "    output_[2][5] = deep\n",
        "    np.savetxt(filename + \".mm\", output_, delimiter = \", \", fmt=\"%1.6f\")\n",
        "  \n",
        "\n",
        "imported_data,_ = librosa.load(input_filename, sr = rate, offset=start_secs, duration=duration_from_start_secs, mono = True)\n",
        "filename = os.path.basename(input_filename)\n",
        "\n",
        "#print(\"  ...ANALYZING\")\n",
        "#print(\"\")\n",
        "#print(\"  ####################################\")\n",
        "print(\"  #   number of samples:  \", len(imported_data))\n",
        "#print(\"  ####################################\")\n",
        "#print(\"\")\n",
        "\n",
        "mel_filter, mel_inversion_filter, window = initialize(fftsize, input_dim)\n",
        "minin, maxin, input_data = analyze_data(imported_data, filename, fftsize, windowskip, input_dim, window, mel_filter)\n",
        "# HAVE THIS GUY RETURN THE INPUT_DATA AND THE FFT DATA\n",
        "np.savetxt(filename + \".minmax\", np.asarray([[minin, maxin]]), delimiter = \", \")\n",
        "# print(\"  ...INITIALIZING AUTOENCODER\")\n",
        "vae, encoder, decoder, training_decoder = init_autoencoder_shallow(input_dim, intermediate_dim, encoded_dim, learning_rate)\n",
        "# print(\"  ...TRAINING\")\n",
        "at = time.time()\n",
        "vae, encoder, decoder, training_decoder, scale_mult, scale_subtract = train(filename, vae, encoder, decoder, training_decoder, input_data, min_delta, regression_patience, batch_size, 0)\n",
        "write_mm(filename, minin, maxin, scale_mult, scale_subtract, input_dim, intermediate_dim, encoded_dim, 0)\n",
        "print(\"   ... time spent training:\", time.time()-at)\n",
        "\n",
        "#print(\"\")\n",
        "#print(quality, \"quality\")\n",
        "\n",
        "z_encoded = encoder.predict(input_data)\n",
        "output_data = training_decoder.predict(z_encoded[0])\n",
        "difference = np.abs(np.subtract(input_data, output_data))\n",
        "\n",
        "#print(\"\")\n",
        "print(\"    ... maximum reconstruction error:\", np.amax(difference))\n",
        "print(\"    ... average reconstruction error:\", np.average(difference))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download trained model\n",
        "\n",
        "fileout = \"/content/\" + filename + \".\" + quality + \".zip\"\n",
        "print(fileout)\n",
        "file1 = input_filename\n",
        "file2 = \"/content/\" + filename + \".fft.dec\"\n",
        "file3 = \"/content/\" + filename + \".mm\"\n",
        "!zip -jq $fileout $file1 $file2 $file3\n",
        "\n",
        "from google.colab import files\n",
        "files.download(fileout)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "bkW1LZuWS-w3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Interact!\n",
        "duration_secs = 3 #@param {type:\"integer\"}\n",
        "window_size = 1024 #@param {type:\"integer\"}\n",
        "continuous_update = False #@param {type:\"boolean\"}\n",
        "loop = True #@param {type:\"boolean\"}\n",
        "\n",
        "fftsize = 16384\n",
        "rate = 44100\n",
        "window_size1 = window_size\n",
        "number_of_windows1 = int(round(rate * duration_secs / window_size1))\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "from IPython.display import display, Audio\n",
        "from ipywidgets import interactive_output, FloatSlider, HBox\n",
        "%cd /content\n",
        "if not os.path.exists('autocoder'):\n",
        "  !git clone --depth 1 -q https://github.com/eyaler/autocoder\n",
        "%cd /content/autocoder/code\n",
        "import autocoderlib as ac\n",
        "%cd /content\n",
        "\n",
        "def gen_phase1(sz_):\n",
        "    phase = (np.random.rand( 1, int(sz_ / 2) + 1) * math.pi * 2.- math.pi).astype(np.float32)\n",
        "    phase[0, 0] = 0.;\n",
        "    phase[0, (int)(sz_ / 2)] = 0.;\n",
        "    return(phase)\n",
        "\n",
        "def set_brightness1(fftsize, brightness):\n",
        "    global brightness1_\n",
        "    brightness1_ = np.zeros((int)(fftsize / 2), dtype=np.float32)\n",
        "    for i in range(0, (int)(fftsize / 2)):\n",
        "        brightness1_[i] = pow(i/((int)(fftsize / 2)), brightness)\n",
        "    brightness1_ = np.multiply(brightness1_, 10.)\n",
        "\n",
        "def jit_lopas1(a,b, f):\n",
        "    a = np.multiply(a, f)\n",
        "    b = np.multiply(b, 1. - f)\n",
        "    a = np.add(a, b)\n",
        "    return(a)\n",
        "\n",
        "minin1, maxin1, scale_mult1, scale_subtract1, input_dim1, intermediate_dim1, encoded_dim1, deep1 = ac.read_mm(filename)\n",
        "decoder1, input_details1, output_details1 = ac.load_lite(filename, \"decoder\")\n",
        "mel_filter1, mel_inversion_filter1, window1 = ac.initialize(fftsize, input_dim1)\n",
        "\n",
        "internal_vector1 = np.zeros((1, encoded_dim1))\n",
        "output1 = np.zeros(number_of_windows1 * window_size1)\n",
        "\n",
        "\n",
        "se1 = np.zeros(window_size1, dtype=np.float32)\n",
        " \n",
        "    \n",
        "def signal(brightness=0, smoothing=0.1, filter=1, l1=0, l2=0, l3=0, l4=0, l5=0, l6=0, l7=0, l8=0):\n",
        "\n",
        "    set_brightness1(fftsize, brightness)\n",
        "    internal_vector1[0,] = [l1,l2,l3,l4,l5,l6,l7,l8]\n",
        "    p_m = ac.decode(decoder1, deep1, scale_mult1, scale_subtract1, internal_vector1)\n",
        "    ca1 = np.zeros((1, int(fftsize / 2 + 1)), dtype=np.float32)\n",
        "    ca1[0,0:int(fftsize/2)] = p_m.dot(mel_inversion_filter1)\n",
        "    ca1 = ca1.clip(0., filter)\n",
        "    ca1[0,0:int(fftsize/2)] = np.abs(np.multiply(ca1[0,0:int(fftsize/2)], brightness1_))\n",
        "    ca1[0,0] = 0.\n",
        "   \n",
        "    smooth1 = np.zeros((1, int(fftsize / 2 + 1)), dtype=np.float32)\n",
        "    sout1 = np.zeros((fftsize), dtype=np.float32)\n",
        "    first = True\n",
        "    \n",
        "    def callback1():\n",
        "\n",
        "      nonlocal smooth1\n",
        "      nonlocal sout1\n",
        "      nonlocal first\n",
        "\n",
        "      # DECODE\n",
        "      smooth1 = jit_lopas1(ca1, smooth1, smoothing if not first else 1)\n",
        "      first = False\n",
        "      \n",
        "      # GENERATE NOISE TO USE AS RECONSTRUCTION PHASE\n",
        "      ph = gen_phase1(fftsize)\n",
        "\n",
        "      # CONVERT BACK TO A SIGNAL\n",
        "      co = np.zeros(int(fftsize / 2 + 1), dtype='complex64')\n",
        "      co.real = np.multiply(smooth1.real, np.cos(ph))\n",
        "      co.imag = np.multiply(smooth1.imag, np.sin(ph))\n",
        "      cs = np.multiply(np.fft.irfft(co), window1)\n",
        "\n",
        "      sout1[0:(fftsize - window_size1)] = sout1[window_size1:fftsize]\n",
        "      sout1[(fftsize - window_size1):fftsize] = se1\n",
        "      sout1 = np.add(sout1, cs)[0,]\n",
        "      return np.multiply(sout1[0:window_size1].astype(np.float32), 250.)    \n",
        "      \n",
        "    for i in range(number_of_windows1):\n",
        "        output1[i * window_size1:(i + 1) * window_size1] = callback1()\n",
        "    a = Audio(data=output1, rate=rate, autoplay=True)\n",
        "    if loop:\n",
        "      a.autoplay_attr = lambda: 'autoplay=\"autoplay\" loop=\"loop\"'\n",
        "    display(a)\n",
        "\n",
        "def get_slider(desc, value=0.0, min_val=0, max_val=1):\n",
        "  return FloatSlider(description=desc, value=value, min=min_val, max=max_val, step=.01, continuous_update=continuous_update, orientation='vertical')\n",
        "\n",
        "brightness1=get_slider('brightness', max_val=2)\n",
        "smoothing1=get_slider('smoothing', 0.1)\n",
        "filter1=get_slider('filter', 1, min_val=0.01, max_val=2)\n",
        "l1=get_slider('l1')\n",
        "l2=get_slider('l2')\n",
        "l3=get_slider('l3')\n",
        "l4=get_slider('l4')\n",
        "l5=get_slider('l5')\n",
        "l6=get_slider('l6')\n",
        "l7=get_slider('l7')\n",
        "l8=get_slider('l8')\n",
        "ui = HBox([brightness1, smoothing1, filter1, l1,l2,l3,l4,l5,l6,l7,l8])\n",
        "out = interactive_output(signal, {'brightness':brightness1, 'smoothing':smoothing1, 'filter':filter1, 'l1':l1,'l2':l2,'l3':l3,'l4':l4,'l5':l5,'l6':l6,'l7':l7,'l8':l8})\n",
        "display(ui, out)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "TAnrDf0RQMrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Generate Random Walk\n",
        "#@markdown Note: granular mode is experimental/WIP\n",
        "mode = 'spectral' #@param ['spectral', 'granular']\n",
        "latent_random_max = 10 #@param {type: 'number'}\n",
        "latent_random_pow = 1 #@param {type: 'number'}\n",
        "brightness = 0 #@param {type: 'slider', min:0, max:2, step:0.01}\n",
        "smoothing = 0.1 #@param {type: 'slider', min:0.01, max:1, step:0.01}\n",
        "filter = 1 #@param {type:\"number\"}\n",
        "duration_secs = 30 #@param {type: 'number'}\n",
        "window_size = 1024 #@param {type: 'integer'}\n",
        "grain_size = 1024 #@param {type: 'integer'}\n",
        "training_skip = 1024 #@param {type: 'integer'}\n",
        "max_rand_step = 10 #@param {type: 'integer'}\n",
        "rand_pow = 1 #@param {type: 'number'}\n",
        "group_n = 100 #@param {type: 'integer'}\n",
        "\n",
        "\n",
        "%cd /content\n",
        "if not os.path.exists('autocoder'):\n",
        "  !git clone --depth 1 -q https://github.com/eyaler/autocoder\n",
        "%cd /content/autocoder/code\n",
        "import autocoderlib as ac\n",
        "%cd /content\n",
        "\n",
        "import sys\n",
        "import numpy as np\n",
        "import math\n",
        "import scipy\n",
        "import time\n",
        "import random\n",
        "from IPython.display import display, Audio\n",
        "\n",
        "fftsize = 16384\n",
        "rate = 44100\n",
        "number_of_windows = int(round(rate * duration_secs / window_size))\n",
        "\n",
        "if mode == 'spectral':\n",
        "  mode = 'render'\n",
        "argv = [None, '-' + mode, filename, number_of_windows]\n",
        "if mode == 'render':\n",
        "  argv += [fftsize, window_size]\n",
        "elif mode == 'granular':\n",
        "  argv += [grain_size, training_skip, window_size, max_rand_step, rand_pow, group_n]\n",
        "\n",
        "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
        "\n",
        "#internal_vector = 0\n",
        "#brightness_ = 0\n",
        "#smooth = 0\n",
        "#ca = 0\n",
        "#sout = 0\n",
        "#se = 0\n",
        "color = ac.color\n",
        "\n",
        "if(argv[1] == \"-help\" or argv[1] == '-h'):\n",
        "    print()\n",
        "    print(\"       python3 ./autocoder_generate.py \"+color.CYAN+\"-play[-p]\"+color.END+\" \"+color.GREEN+\"input_file.wav\"+color.END+\" fftsize[4096] dac_buffersize[512] \")\n",
        "    print()\n",
        "    print(\"                Generates and plays an output based on the input_file.wav \")\n",
        "    print(\"                model via pyAudio.\")\n",
        "    print()\n",
        "    print(\"       python3 ./autocoder_generate.py \"+color.CYAN+\"-render[-r]\"+color.END+\" \"+color.GREEN+\"input_file.wav\"+color.END+\" n fftsize[4096] skip[512]\")\n",
        "    print()\n",
        "    print(\"                Generates and saves n windows based on the input_file.wav \")\n",
        "    print(\"                model to a file named input_file.wav-out.wav.\")\n",
        "    print()\n",
        "    print(\"       python3 ./autocoder_generate.py \"+color.CYAN+\"-granular[-g]\"+color.END+\" \"+color.GREEN+\"input_file.wav\"+color.END+\" n grainsize trainingskip windowskip rand_n rand_p\")\n",
        "    print()\n",
        "    print(\"                Generates and saves n grains based on similarities within\")\n",
        "    print(\"                the input_file.wav model to a file named input_file.wav-out.wav.\")\n",
        "    print()\n",
        "    print(\"                Each new grain is selected from the rand_n most similar\")\n",
        "    print(\"                candidates. rand_p weights the probability either closer\")\n",
        "    print(\"                (p > 1.) or further (p < 1.) away from the start point\")\n",
        "    print(\"                along the similarity metric axis.\")\n",
        "    print()\n",
        "    print(\"       python3 ./autocoder_generate.py \"+color.CYAN+\"-autocode[-a]\"+color.END+\" \"+color.GREEN+\"carrier_file.wav modulator_file.wav\"+color.END+\" fftsize windowskip *args:manipulations\")\n",
        "    print()\n",
        "    print(\"                The autocoder takes an input model (carrier_file.wav) and\")\n",
        "    print(\"                a modulator file (modulator_file.wav), and encodes and  \")\n",
        "    print(\"                decodes the modulator using the carrier model. A vector \")\n",
        "    print(\"                of the same size as the encoded dimension can be provided\")\n",
        "    print(\"                to reorder and invert the mapping of each dimension in the\")\n",
        "    print(\"                input file onto the output model.\")\n",
        "    print()\n",
        "    exit()\n",
        "\n",
        "def gen_internal_vector_(random_max, random_pow):\n",
        "    global internal_vector\n",
        "    internal_vector[0,] =  np.clip(np.add(internal_vector, np.divide(np.subtract(np.power(np.random.rand(1, 8), random_pow), .5), random_max)), 0., 1.)\n",
        "\n",
        "def gen_phase(sz_):\n",
        "    phase = (np.random.rand( 1, int(sz_ / 2) + 1) * math.pi * 2.- math.pi).astype(np.float32)\n",
        "    phase[0, 0] = 0.;\n",
        "    phase[0, (int)(sz_ / 2)] = 0.;\n",
        "    return(phase)\n",
        "\n",
        "def set_brightness(fftsize, brightness):\n",
        "    global brightness_\n",
        "    brightness_ = np.zeros((int)(fftsize / 2), dtype=np.float32)\n",
        "    for i in range(0, (int)(fftsize / 2)):\n",
        "        brightness_[i] = pow(i/((int)(fftsize / 2)), brightness)\n",
        "    brightness_ = np.multiply(brightness_, 10.)\n",
        "\n",
        "def jit_lopas(a,b, f):\n",
        "    a = np.multiply(a, f)\n",
        "    b = np.multiply(b, 1. - f)\n",
        "    a = np.add(a, b)\n",
        "    return(a)\n",
        "\n",
        "def callback(in_data, frame_count, time_info, status):\n",
        "\n",
        "    global smooth\n",
        "    global sout\n",
        "\n",
        "    # DECODE\n",
        "    gen_internal_vector_(latent_random_max, latent_random_pow)\n",
        "    p_m = ac.decode(decoder, deep, scale_mult, scale_subtract, internal_vector)\n",
        "    ca = np.zeros((1, int(fftsize / 2 + 1)), dtype=np.float32)\n",
        "    ca[0,0:int(fftsize/2)] = p_m.dot(mel_inversion_filter)\n",
        "    ca = ca.clip(0., filter)\n",
        "    ca[0,0:int(fftsize/2)] = np.abs(np.multiply(ca[0,0:int(fftsize/2)], brightness_))\n",
        "    ca[0,0] = 0.\n",
        "\n",
        "    smooth = jit_lopas(ca, smooth, smoothing)\n",
        "\n",
        "    # GENERATE NOISE TO USE AS RECONSTRUCTION PHASE\n",
        "    ph = gen_phase(fftsize)\n",
        "\n",
        "    # CONVERT BACK TO A SIGNAL\n",
        "    co = np.zeros(int(fftsize / 2 + 1), dtype='complex64')\n",
        "    co.real = np.multiply(smooth.real, np.cos(ph))\n",
        "    co.imag = np.multiply(smooth.imag, np.sin(ph))\n",
        "    cs = np.multiply(np.fft.irfft(co), window)\n",
        "\n",
        "    sout[0:(fftsize - frame_count)] = sout[frame_count:fftsize]\n",
        "    sout[(fftsize - frame_count):fftsize] = se\n",
        "    sout = np.add(sout, cs)[0,]\n",
        "    return(np.multiply(sout[0:frame_count].astype(np.float32), 250.), 0)\n",
        "\n",
        "\n",
        "min_a = np.zeros(8)\n",
        "max_a = np.zeros(8)\n",
        "min_a.fill(1000000)\n",
        "max_a.fill(-1000000)\n",
        "\n",
        "def autocode_norm_factors(in_data):\n",
        "    global min_a\n",
        "    global max_a\n",
        "\n",
        "    amp, ph, norm_factor = ac.analyze_normalized(in_data, window, mel_filter)\n",
        "    in_data = ac.encode(encoder, deep, scale_mult, scale_subtract, amp)\n",
        "    t = np.zeros((2, 8))\n",
        "    t[0,] = in_data\n",
        "    t[1,] = min_a\n",
        "    min_a = np.amin(t, axis = 0)\n",
        "    t[1,] = max_a\n",
        "    max_a = np.amax(t, axis = 0)\n",
        "\n",
        "\n",
        "def autocode(in_data, offset, scale, reorder, norm_min, norm_max):\n",
        "\n",
        "    global smooth\n",
        "\n",
        "    # DECODE\n",
        "    amp, ph, norm_factor = ac.analyze_normalized(in_data, window, mel_filter)\n",
        "    in_data = ac.encode(encoder, deep, scale_mult, scale_subtract, amp)\n",
        "    in_data = np.divide(np.subtract(in_data,norm_min), np.subtract(norm_max, norm_min))\n",
        "\n",
        "\n",
        "    in_data = in_data[reorder]\n",
        "    #in_data = np.add(np.multiply(in_data, invert_mult), invert_add)\n",
        "    in_data = np.clip(np.add(np.multiply(in_data, scale), offset), 0, 1)\n",
        "    print(in_data)\n",
        "    #print(np.add(np.multiply(in_data, scale), offset))\n",
        "    p_m = np.multiply(ac.decode(decoder, deep, scale_mult, scale_subtract, in_data), norm_factor)\n",
        "    ca = np.zeros((1, int(fftsize / 2 + 1)), dtype=np.float32)\n",
        "    ca[0,0:int(fftsize/2)] = p_m.dot(mel_inversion_filter)\n",
        "    ca = ca.clip(0., filter)\n",
        "    ca[0,0:int(fftsize/2)] = np.abs(np.multiply(ca[0,0:int(fftsize/2)], brightness_))\n",
        "    ca[0,0] = 0.\n",
        "\n",
        "    #smooth = jit_lopas(ca, smooth, smoothing)\n",
        "    smooth = ca\n",
        "\n",
        "    # CONVERT BACK TO A SIGNAL\n",
        "    co = np.zeros(int(fftsize / 2 + 1), dtype='complex64')\n",
        "    co.real = np.multiply(smooth.real, np.cos(ph))\n",
        "    co.imag = np.multiply(smooth.imag, np.sin(ph))\n",
        "\n",
        "    return(np.multiply(np.fft.irfft(co), window))\n",
        "\n",
        "\n",
        "if(argv[1] == '-test'):\n",
        "    # read parameters\n",
        "    minin, maxin, scale_mult, scale_subtract, input_dim, intermediate_dim, encoded_dim, deep = ac.read_mm(argv[2])\n",
        "    # load both models\n",
        "    decoder, input_details, output_details = ac.load_lite(argv[2], \"decoder\")\n",
        "    fft_decoder, fft_input_details, fft_output_details = ac.load_lite(argv[2] + \".fft\", \"decoder\")\n",
        "    mel_filter, mel_inversion_filter, window = ac.initialize(4096, input_dim)\n",
        "    print(\"\")\n",
        "    print(input_details)\n",
        "    print(\"\")\n",
        "    print(output_details)\n",
        "    print(\"\")\n",
        "    print(fft_input_details)\n",
        "    print(\"\")\n",
        "    print(fft_output_details)\n",
        "    print(\"\")\n",
        "    p_m = ac.decode(decoder, 0, scale_mult, scale_subtract, [0, 0, 0, 0, 0, 0, 0, 0])\n",
        "    print(p_m)\n",
        "    print(\"\")\n",
        "    p_n = ac.decode(fft_decoder, 2, scale_mult, scale_subtract, [0, 0, 0, 0, 0, 0, 0, 0])\n",
        "    print(p_n[0:256])\n",
        "\n",
        "if(argv[1] == \"-render\" or argv[1] == \"-r\"):\n",
        "    '''\n",
        "    print(\"\")\n",
        "    print(\"------------------------------\")\n",
        "    print(\"|         RENDERING          |\")\n",
        "    print(\"------------------------------\")\n",
        "    print(\"\")\n",
        "    '''\n",
        "\n",
        "    filename_ = argv[2]\n",
        "    n = int(argv[3])\n",
        "    fftsize = int(argv[4])\n",
        "    skip = int(argv[5])\n",
        "\n",
        "    minin, maxin, scale_mult, scale_subtract, input_dim, intermediate_dim, encoded_dim, deep = ac.read_mm(argv[2])\n",
        "    decoder, input_details, output_details = ac.load_lite(argv[2], \"decoder\")\n",
        "    set_brightness(fftsize, brightness)\n",
        "    mel_filter, mel_inversion_filter, window = ac.initialize(fftsize, input_dim)\n",
        "\n",
        "    ### INITIALIZE GLOBAL BUFFERS, TRY TO GET RID OF THESE\n",
        "    output = np.zeros(n * skip)\n",
        "    smooth = np.zeros((1, int(fftsize / 2 + 1)), dtype=np.float32)\n",
        "    internal_vector = np.zeros((1, encoded_dim))\n",
        "    sout = np.zeros((fftsize), dtype=np.float32)\n",
        "    se = np.zeros(skip, dtype=np.float32)\n",
        "\n",
        "    for i in range(n):\n",
        "        output[i * skip:(i + 1) * skip], paval = callback(0, skip, 0, 0)\n",
        "\n",
        "    scipy.io.wavfile.write(argv[2] + \"-out.wav\", rate, (32767 * np.divide(output, np.amax(np.abs(output)))).astype(np.int16))\n",
        "\n",
        "\n",
        "elif(argv[1] == \"-granular\" or argv[1] == \"-g\"):\n",
        "    '''\n",
        "    print(\"\")\n",
        "    print(\"------------------------------\")\n",
        "    print(\"| ORDERED GRANULAR RENDERING |\")\n",
        "    print(\"------------------------------\")\n",
        "    print(\"\")\n",
        "    '''\n",
        "    filename_ = argv[2]\n",
        "    n = int(argv[3])\n",
        "    grainsize = int(argv[4])\n",
        "    trainingskip = int(argv[5])   ### GET THIS FROM THE MM FILE,\n",
        "    windowskip = int(argv[6])\n",
        "    max_rand_step = int(argv[7])\n",
        "    rand_pow =  float(argv[8])\n",
        "    group_n =  int(argv[9])\n",
        "\n",
        "\n",
        "    minin, maxin, scale_mult, scale_subtract, input_dim, intermediate_dim, encoded_dim, deep = ac.read_mm(argv[2])\n",
        "    decoder, input_details, output_details = ac.load_lite(argv[2], \"decoder\")\n",
        "    set_brightness(grainsize, brightness)\n",
        "    mel_filter, mel_inversion_filter, window = ac.initialize(grainsize, input_dim)\n",
        "\n",
        "    output = np.zeros(n * windowskip)\n",
        "\n",
        "    # READ THE WAVEFILE\n",
        "    wavefile = librosa.load(input_filename, sr = rate, offset=start_secs, duration=duration_from_start_secs, mono = True)[0]\n",
        "    #print(\"   WAVEFILE LENGTH:\", wavefile.shape)\n",
        "\n",
        "    group = group_n > 1\n",
        "    \n",
        "    input_data = ac.import_training_data(filename_)\n",
        "\n",
        "    minin, maxin, scale_mult, scale_subtract, input_dim, intermediate_dim, encoded_dim, deep = ac.read_mm(argv[2])\n",
        "    encoder, input_details, output_details = ac.load_lite(filename_, \"encoder\")\n",
        "\n",
        "    encoded_input = np.zeros((input_data.shape[0], encoded_dim))\n",
        "\n",
        "    for i in range(0, encoded_input.shape[0]):\n",
        "        encoded_input[i,] = ac.encode(encoder, deep, scale_mult, scale_subtract, input_data[i,])\n",
        "\n",
        "    if(group):\n",
        "        t = np.zeros((int(encoded_input.shape[0]/group_n), encoded_input.shape[1]))\n",
        "        sd = np.zeros((int(encoded_input.shape[0]/group_n), encoded_input.shape[1]))\n",
        "        for i in range(0, int(encoded_input.shape[0]/group_n)):\n",
        "            t[i,] = np.sum(encoded_input[i * group_n:(i + 1) * group_n,], axis = 0) / group_n\n",
        "            sd[i,] = np.std(encoded_input[i * group_n:(i + 1) * group_n,], axis = 0)\n",
        "        encoded_input = t\n",
        "\n",
        "    distances = np.zeros((encoded_input.shape[0], encoded_input.shape[0]))\n",
        "\n",
        "    for i in range(0, distances.shape[0]):\n",
        "        for j in range(0, distances.shape[0]):\n",
        "            if(group):\n",
        "                distances[i,j] = np.sum(np.multiply(np.abs(np.subtract(t[i,], t[j,])), np.subtract(1, sd[j,])))\n",
        "            else:\n",
        "                distances[i,j] = np.sum(np.abs(np.subtract(encoded_input[i,], encoded_input[j,])))\n",
        "\n",
        "    n_returns = min([int(max_rand_step), distances.shape[0] - 1])\n",
        "\n",
        "    if(group):\n",
        "        order = np.zeros((t.shape[0], n_returns), dtype='int')\n",
        "        for i in range(0, t.shape[0]):\n",
        "            order[i,] = np.argsort(distances[i,])[1:n_returns + 1]\n",
        "    else:\n",
        "        order = np.zeros((encoded_input.shape[0], n_returns), dtype='int')\n",
        "        for i in range(0, encoded_input.shape[0]):\n",
        "            order[i,] = np.argsort(distances[i,])[1:n_returns + 1]\n",
        "    \n",
        "    #print(\"   ORDER FILE SHAPE:\", order.shape)\n",
        "\n",
        "    reconstructed = np.zeros((n, grainsize))\n",
        "\n",
        "    index_ =  np.random.randint(0, order.shape[0])\n",
        "\n",
        "    for i in range(n):\n",
        "        # 2. GET THE GRAIN AND WINDOW IT\n",
        "        reconstructed[i,] = np.multiply(wavefile[(index_ * trainingskip):((index_ * trainingskip)+ grainsize)], window)\n",
        "\n",
        "        # 3. RANDOM WALK\n",
        "        index_ = order[index_, int(pow(random.random(), rand_pow) * n_returns)]\n",
        "\n",
        "    output = np.zeros(reconstructed.shape[0] * windowskip + grainsize)\n",
        "\n",
        "    for i in range(reconstructed.shape[0]):\n",
        "        output[i * windowskip:i * windowskip + grainsize] = np.add(output[i * windowskip:i * windowskip + grainsize], reconstructed[i,])\n",
        "\n",
        "    scipy.io.wavfile.write(argv[2] + \"-out.wav\", rate, (32767 * np.divide(output, np.amax(np.abs(output)))).astype(np.int16))\n",
        "\n",
        "elif(argv[1] == \"-autocode\" or argv[1] == \"-a\"):\n",
        "    '''\n",
        "    print(\"\")\n",
        "    print(\"------------------------------\")\n",
        "    print(\"|         AUTOCODING         |\")\n",
        "    print(\"------------------------------\")\n",
        "    print(\"\")\n",
        "    '''\n",
        "\n",
        "    model_filename = argv[2]\n",
        "    input_filename = argv[3]\n",
        "    fftsize = int(argv[4])\n",
        "    windowskip = int(argv[5])\n",
        "    offset = 0 #float(argv[6])\n",
        "    scale = 1 #float(argv[7])\n",
        "\n",
        "    minin, maxin, scale_mult, scale_subtract, input_dim, intermediate_dim, encoded_dim, deep = ac.read_mm(model_filename)\n",
        "    decoder, input_details, output_details = ac.load_lite(model_filename, \"decoder\")\n",
        "    encoder, input_details, output_details = ac.load_lite(model_filename, \"encoder\")\n",
        "    set_brightness(fftsize, brightness)\n",
        "    mel_filter, mel_inversion_filter, window = ac.initialize(fftsize, input_dim)\n",
        "\n",
        "    reorder = np.zeros((encoded_dim), dtype = np.int)\n",
        "    scale = np.zeros((encoded_dim), dtype = np.float32)\n",
        "    offset = np.zeros((encoded_dim), dtype = np.float32)\n",
        "\n",
        "\n",
        "    for i in range(0, encoded_dim):\n",
        "        reorder[i] = int(argv[6 + i])\n",
        "        scale[i] = float(argv[6 + encoded_dim + i])\n",
        "        offset[i] = float(argv[6 + encoded_dim + encoded_dim + i])\n",
        "\n",
        "\n",
        "    #reorder = np.subtract(np.abs(reorder), 1)\n",
        "\n",
        "    # READ THE WAVEFILE\n",
        "    wavefile = librosa.load(input_filename, sr = rate, offset=start_secs, duration=duration_from_start_secs,mono = True)[0]\n",
        "\n",
        "    n = int((wavefile.shape[0] - fftsize) / windowskip)\n",
        "\n",
        "    for i in range(n):\n",
        "        # 2. GET THE GRAIN AND WINDOW IT\n",
        "        autocode_norm_factors(np.multiply(wavefile[(i * windowskip):((i * windowskip)+ fftsize)], window))\n",
        "\n",
        "    #np.divide(np.subtract(a, np.amin(a,axis=0)), np.subtract(np.amax(a, axis = 0), np.amin(a, axis = 0)))\n",
        "    #quit()\n",
        "\n",
        "    reconstructed = np.zeros((n, fftsize))\n",
        "\n",
        "    # NORMALIZE THE INPUT\n",
        "    for i in range(n):\n",
        "        # 2. GET THE GRAIN AND WINDOW IT\n",
        "        reconstructed[i,] = autocode(np.multiply(wavefile[(i * windowskip):((i * windowskip)+ fftsize)], window), offset, scale, reorder, min_a, max_a)\n",
        "\n",
        "\n",
        "    output = np.zeros(reconstructed.shape[0] * windowskip + fftsize)\n",
        "\n",
        "    for i in range(reconstructed.shape[0]):\n",
        "        output[i * windowskip:i * windowskip + fftsize] = np.add(output[i * windowskip:i * windowskip + fftsize], reconstructed[i,])\n",
        "\n",
        "    scipy.io.wavfile.write(argv[2] + \"-out.wav\", rate, (32767 * np.divide(output, np.amax(np.abs(output)))).astype(np.int16))\n",
        "display(Audio(argv[2] + \"-out.wav\", rate=rate, autoplay=True))"
      ],
      "metadata": {
        "id": "awrjxfHIGmLu",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download output file\n",
        "\n",
        "from google.colab import files\n",
        "files.download(argv[2] + \"-out.wav\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "faNdutV7Yt6Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "autocoder",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}